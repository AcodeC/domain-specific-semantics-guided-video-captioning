{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mh/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import load\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pydot\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from numpy import argmax\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from keras.utils import CustomObjectScope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import utils and evaluate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from evaluate import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the ResNet-152, C3D and semantic features for training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 337\n",
      "Descriptions: train=337\n",
      "C2D: train=337\n",
      "C3D: train=337\n",
      "Semantic: train=337\n",
      "Descriptions: train=100\n",
      "C2D: train=100\n",
      "C3D: train=100\n",
      "Semantic: train=100\n"
     ]
    }
   ],
   "source": [
    "#load the train ids for a particular class\n",
    "class_file = 'data/msvd_classes/cook_train_ID.txt'\n",
    "train = load_set(class_file)\n",
    "print('Number of training videos: %d' % len(train))\n",
    "\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_descriptions('data/descriptions_processed.txt', train)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))\n",
    "\n",
    "#load c2d features\n",
    "train_c2d_features = load_video_features('data/msvd_resnet152_features.pkl', train)\n",
    "print('C2D: train=%d' % len(train_c2d_features))\n",
    "\n",
    "#load c3d features\n",
    "train_c3d_features = load_video_features('data/msvd_c3d_features.pkl', train)\n",
    "print('C3D: train=%d' % len(train_c3d_features))\n",
    "\n",
    "#load semantic features\n",
    "train_semantic_features = load_video_features('data/msvd_semantic_features.pkl', train)\n",
    "print('Semantic: train=%d' % len(train_semantic_features))\n",
    "\n",
    "# load validtaion set\n",
    "filename = 'data/msvd_classes/cook_val_ID.txt'\n",
    "test = load_set(filename)\n",
    "print('Dataset: %d' % len(test))\n",
    "\n",
    "# descriptions\n",
    "test_descriptions = load_descriptions('data/descriptions_processed.txt', test)\n",
    "print('Descriptions: test=%d' % len(test_descriptions))\n",
    "\n",
    "#load c2d features\n",
    "test_c2d_features = load_video_features('data/msvd_resnet152_features.pkl', test)\n",
    "print('C2D: test=%d' % len(test_c2d_features))\n",
    "\n",
    "#load c3d features\n",
    "test_c3d_features = load_video_features('data/msvd_c3d_features.pkl', test)\n",
    "print('C3D: test=%d' % len(test_c3d_features))\n",
    "\n",
    "#load semantic features\n",
    "test_semantic_features = load_video_features('data/msvd_semantic_features.pkl', test)\n",
    "print('Semantic: test=%d' % len(test_semantic_features))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Create tokenizer and load the old model trained with the videos belonging to all the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 3084\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          524416      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 49)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 49, 100)      984200      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 556)          0           concatenate_1[0][0]              \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 49, 256)      365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 49, 556)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 49, 128)      32896       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 49, 684)      0           repeat_vector_1[0][0]            \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          832512      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 9842)         2529394     bidirectional_1[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 5,531,258\n",
      "Trainable params: 4,547,058\n",
      "Non-trainable params: 984,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the tokenizer for MSVD descriptions\n",
    "desc = to_lines(train_descriptions)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(desc)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "max_length = 40\n",
    "\n",
    "\n",
    "#Load the good model already built for captioning\n",
    "model_old = load_model('pretrained_model_10.h5')\n",
    "model_old.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model with new domain specific decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          524416      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 49)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 49, 100)      984200      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 556)          0           concatenate_1[0][0]              \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 49, 256)      365568      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 49, 556)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 49, 128)      32896       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 49, 684)      0           repeat_vector_1[0][0]            \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 128)          383488      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "final_dense (Dense)             (None, 874)          112746      bidirectional_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 2,665,586\n",
      "Trainable params: 496,234\n",
      "Non-trainable params: 2,169,352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#load ouput from concatenate layer\n",
    "layer_name = 'concatenate_3'\n",
    "model= Model(inputs=model_old.input, outputs=model_old.get_layer(layer_name).output)\n",
    "\n",
    "# make the previous layers not trainable\n",
    "for layer in model.layers[:13]:\n",
    "    layer.trainable = False\n",
    "#take the output from the previous layers\n",
    "x = model.output\n",
    "\n",
    "# Add BLSTM layer\n",
    "blstm = Bidirectional(LSTM(64))(x)\n",
    "\n",
    "#Add an attention layer\n",
    "att=Attention(max_length)(blstm)\n",
    "\n",
    "#add dense layer\n",
    "outputs = Dense(vocab_size, activation='softmax',name='final_dense')(blstm)\n",
    "\n",
    "model = Model(inputs=model_old.input, outputs=outputs)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "#save model to file\n",
    "plot_model(model, to_file='/home/mh/mywork/video_caption_domain/model_cook/model_cook.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the domain specific model save after training\n",
    "steps = len(train_descriptions)\n",
    "\n",
    "# create the data generator\n",
    "generator = data_generator(train_descriptions, train_c2d_features, train_c3d_features, train_semantic_features, tokenizer, max_length)\n",
    "\n",
    "# fit the model to train the decoder\n",
    "model.fit_generator(generator, epochs=50, steps_per_epoch=steps, verbose=1)\n",
    "# save model\n",
    "model.save('/home/mh/mywork/video_caption_domain/model_cook/model_' + str(i) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
